{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SlantDetector.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOzCBpOvI289WCUKZsjYaj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knk190001/SlantClassification/blob/master/SlantDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4s_T-tJIZyW",
        "colab_type": "code",
        "outputId": "9ef6f9bc-447e-4368-8d55-8393b96c2271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/knk190001/SlantClassification.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SlantClassification' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtFwHuT91ZEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txLKd6x711r9",
        "colab_type": "code",
        "outputId": "217a5b67-6092-4044-ae3c-d7d529b2b0dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data = pd.read_csv('./SlantClassification/tweets.csv')\n",
        "reps = pd.read_json('./SlantClassification/representatives.json')\n",
        "sens = pd.read_json('./SlantClassification/senators.json')\n",
        "\n",
        "def findParty(user):\n",
        "  temp = reps[reps['Twitter_username']==user]\n",
        "  if temp.empty :\n",
        "    temp = sens[sens['Twitter_username']==user]\n",
        "  \n",
        "  if temp.empty:\n",
        "    return\n",
        "  if temp.iloc[0,2] == 'Democratic Party' :\n",
        "    return int(1)\n",
        "  elif temp.iloc[0,2] == 'Republican Party' :\n",
        "    return int(0)\n",
        "\n",
        "data['user'] = data['user'].apply(findParty)\n",
        "\n",
        "data.sample(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67730</th>\n",
              "      <td>1.0</td>\n",
              "      <td>I have a lot of respect for General Mattis and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64203</th>\n",
              "      <td>1.0</td>\n",
              "      <td>There was an incredible feeling of energy and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98733</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Wisconsinites  you can register and vote on El...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10906</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Given the positions he has taken in litigation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31847</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Al is proud to be @HRC endorsed: http://t.co/V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       user                                               text\n",
              "67730   1.0  I have a lot of respect for General Mattis and...\n",
              "64203   1.0  There was an incredible feeling of energy and ...\n",
              "98733   1.0  Wisconsinites  you can register and vote on El...\n",
              "10906   1.0  Given the positions he has taken in litigation...\n",
              "31847   1.0  Al is proud to be @HRC endorsed: http://t.co/V..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvBtKeLGjrcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove(pattern,text):\n",
        "  if isinstance(text,str):\n",
        "    return re.sub(pattern,'',text)\n",
        "  return float('nan')\n",
        "\n",
        "def removeLinks(text):\n",
        "  return remove(r'https?:\\/\\/.*[\\r\\n]*',text)\n",
        "def removeHandles(text):\n",
        "  return remove(r'@\\w{1,15}',text)\n",
        "def removeHashtags(text):\n",
        "  return remove(r'#\\w*[A-Za-z_]+\\w*',text)\n",
        "\n",
        "data['text'] = data['text'].apply(removeLinks).apply(removeHandles).apply(removeHashtags).dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUPqVo5QYs0q",
        "colab_type": "code",
        "outputId": "21f4f400-b280-4ce9-e4fc-015baa5fa558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "data.columns = ['party','text']\n",
        "data = data.dropna()\n",
        "data.head(20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Nancy Pelosi and Adam Schiffs impeachment was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>One of the reasons for the Democrats' impeachm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>It was great to see so many friends tonight at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>READ MY FULL STATEMENT HERE:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. is a foot soldier for Chuck Schumer and the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. is deeply complicit in this grave wrong. In ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>They fear our strong President  who is boldly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>House Democrats have committed a very grave wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>As I have stated from the beginning on multipl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>The Democrats partisan impeachment charade has...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I commend President  for his strong and commit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>RT : EXCLUSIVE  : Doug Jones Has Revealed Hims...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. is a foot soldier for  and the radical left,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. announced this morning that he plans to vote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>So happy for my good friend Rush Limbaugh  Rus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Amen. Thank you, President Trump, for protecti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>The left has swung and missed on impeachment. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Truly an incredible State of the Union address...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I'll be on Fox News tonight with  to preview P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>No one has done more to advance the cause of f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    party                                               text\n",
              "1     0.0  Nancy Pelosi and Adam Schiffs impeachment was ...\n",
              "2     0.0  One of the reasons for the Democrats' impeachm...\n",
              "3     0.0  It was great to see so many friends tonight at...\n",
              "4     0.0                      READ MY FULL STATEMENT HERE: \n",
              "5     0.0  . is a foot soldier for Chuck Schumer and the ...\n",
              "6     0.0  . is deeply complicit in this grave wrong. In ...\n",
              "7     0.0  They fear our strong President  who is boldly ...\n",
              "8     0.0  House Democrats have committed a very grave wr...\n",
              "9     0.0  As I have stated from the beginning on multipl...\n",
              "10    0.0  The Democrats partisan impeachment charade has...\n",
              "11    0.0  I commend President  for his strong and commit...\n",
              "12    0.0  RT : EXCLUSIVE  : Doug Jones Has Revealed Hims...\n",
              "13    0.0  . is a foot soldier for  and the radical left,...\n",
              "14    0.0  . announced this morning that he plans to vote...\n",
              "15    0.0  So happy for my good friend Rush Limbaugh  Rus...\n",
              "16    0.0  Amen. Thank you, President Trump, for protecti...\n",
              "17    0.0  The left has swung and missed on impeachment. ...\n",
              "18    0.0  Truly an incredible State of the Union address...\n",
              "19    0.0  I'll be on Fox News tonight with  to preview P...\n",
              "20    0.0  No one has done more to advance the cause of f..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hkK3qMtMcVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "c129a9fa-8592-47a3-92c9-61acc86ebf14"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNe_O6CTMhyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERE0QpoQ2c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True).dropna()\n",
        "phaseOne = data.head(int(len(data.index) * .75)).reset_index(drop=True)\n",
        "phaseTwo = data.tail(int(len(data.index)*.25)).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDXZw0glTrn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "807d92b4-105e-4fe9-9c2f-d5a423e6ee3b"
      },
      "source": [
        "phaseOne"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Island nations and territories already bear th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Im encouraged that this bill, which passed wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50 yrs ago today people were killed in a deadl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Great photos from my tour through   this week ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Very sad to hear about Charles .He is one of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101324</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Thank you ! Proud to work with you to protect ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101325</th>\n",
              "      <td>1.0</td>\n",
              "      <td>No matter where you come from, no matter who y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101326</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Healthy oceans are vital to a healthy economy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101327</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Unlike the White House proposals, my legislati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101328</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Cronyism is the real .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101329 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        party                                               text\n",
              "0         0.0  Island nations and territories already bear th...\n",
              "1         0.0  Im encouraged that this bill, which passed wit...\n",
              "2         1.0  50 yrs ago today people were killed in a deadl...\n",
              "3         0.0  Great photos from my tour through   this week ...\n",
              "4         0.0  Very sad to hear about Charles .He is one of t...\n",
              "...       ...                                                ...\n",
              "101324    1.0  Thank you ! Proud to work with you to protect ...\n",
              "101325    1.0  No matter where you come from, no matter who y...\n",
              "101326    0.0  Healthy oceans are vital to a healthy economy ...\n",
              "101327    1.0  Unlike the White House proposals, my legislati...\n",
              "101328    0.0                            Cronyism is the real . \n",
              "\n",
              "[101329 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flUKhSifXn5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a40b61ac-3c95-4afe-b5b5-50d419a01b98"
      },
      "source": [
        "phaseTwo"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>\"I am alive today not because of insurance com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>As a former social worker, I've seen first-han...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Today, Vietnam War Veterans Day, we pause to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>\"It's humiliating. Honestly, Bern, it's humili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Words fail.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33771</th>\n",
              "      <td>0.0</td>\n",
              "      <td>The Senate just voted to begin debate on the f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33772</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Reminder:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33773</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NEW AD: Washington is rigged for the well-conn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33774</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Happy Birthday,  45! We hope youre able to fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33775</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I work will work w you when you go back to th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33776 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       party                                               text\n",
              "0        1.0  \"I am alive today not because of insurance com...\n",
              "1        1.0  As a former social worker, I've seen first-han...\n",
              "2        1.0  Today, Vietnam War Veterans Day, we pause to h...\n",
              "3        1.0  \"It's humiliating. Honestly, Bern, it's humili...\n",
              "4        1.0                                        Words fail.\n",
              "...      ...                                                ...\n",
              "33771    0.0  The Senate just voted to begin debate on the f...\n",
              "33772    1.0                                         Reminder: \n",
              "33773    0.0  NEW AD: Washington is rigged for the well-conn...\n",
              "33774    0.0  Happy Birthday,  45! We hope youre able to fin...\n",
              "33775    0.0   I work will work w you when you go back to th...\n",
              "\n",
              "[33776 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpObFuC9Z7qN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fdd614c-5b7d-4c93-bae1-62b66b8cff3a"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"cuda\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print('cpu')\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoUR3aS5am3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = phaseOne.text.values\n",
        "labels = phaseOne.party.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk2JXBeQivdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HGTznPtjAqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d2a48878-74d3-4349-e72a-1a31f3edc439"
      },
      "source": [
        "print('Original: ',tweets[0])\n",
        "print('Tokenized: ',tokenizer.tokenize(tweets[0]))\n",
        "print('Token IDs: ',tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Island nations and territories already bear the brunt of climate change. I'm thrilled to be in the U.S. Virgin Isla \n",
            "Tokenized:  ['island', 'nations', 'and', 'territories', 'already', 'bear', 'the', 'br', '##unt', 'of', 'climate', 'change', '.', 'i', \"'\", 'm', 'thrilled', 'to', 'be', 'in', 'the', 'u', '.', 's', '.', 'virgin', 'isla']\n",
            "Token IDs:  [2479, 3741, 1998, 6500, 2525, 4562, 1996, 7987, 16671, 1997, 4785, 2689, 1012, 1045, 1005, 1049, 16082, 2000, 2022, 1999, 1996, 1057, 1012, 1055, 1012, 6261, 25340]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1SX682ujNIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3c3ebbd-0024-4c39-f800-c951edf8d8e6"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for tweet in tweets:\n",
        "  encoded_tweet = tokenizer.encode(tweet,add_special_tokens=True)\n",
        "  input_ids.append(encoded_tweet)\n",
        "\n",
        "print('Max length: ', max([len(tweet) for tweet in input_ids]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHmWD0_bn4wQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "input_ids = pad_sequences(input_ids,maxlen=MAX_LEN,dtype='long',value=0, truncating='post',padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_fXmPbXodXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_mask = []\n",
        "\n",
        "for tweet in input_ids:\n",
        "  att_mask = [int(token_id>0) for token_id in tweet]\n",
        "  attention_mask.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oXqYGfcpIm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.model_selection import train_test_split\n",
        "\n",
        " train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,labels,random_state=2018,test_size=0.1)\n",
        "\n",
        " train_masks, validation_masks, _, _, = train_test_split(attention_mask,labels,random_state=2018,test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmVcP5ZwqOVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2KlsJPMrnIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs,train_masks,train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs,validation_masks,validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkrxCnlbsoFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7798327-c3fe-4cf1-c4a7-47043d3d2f4d"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12pfRJ1rtE8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsx0GkPtdK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader)*epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBl5Mj-FtxZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds,labels):\n",
        "  pred_flat = np.argmax(preds,axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat==labels_flat)/len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynsd4V12uI3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE6jIktBuduM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30552c1f-77ee-45a9-98f6-dca73c902a9d"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0,epochs):\n",
        "  print('')\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  print('Training...')\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    if step % 400 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].long().to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids,token_type_ids = None, attention_mask = b_input_mask,labels=b_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "  avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  loss_values.append(avg_train_loss)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  eval_loss,eval_accuracy=0,0\n",
        "  nb_eval_steps,nb_eval_examples = 0,0\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(b_input_ids,token_type_ids = None,attention_mask = b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits,label_ids)\n",
        "\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_steps += 1\n",
        "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:41.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:26.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:10.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:54.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:38.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:22.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:06.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epcoh took: 0:19:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:44.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:28.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:12.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:56.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:41.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:25.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:10.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:19:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:45.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:29.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:13.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:42.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:26.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:11.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:19:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:44.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:29.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:13.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:41.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:26.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:10.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:19:31\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE1CEng0zIWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9d1a9cc3-6e3b-4d6e-8719-c9d7b308b872"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams['figure.figsize'] = (12,6)\n",
        "\n",
        "plt.plot(loss_values,'b-o')\n",
        "\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpEIE5F0s6es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1069bc3c-1b4a-409c-ee00-4a72060806b7"
      },
      "source": [
        "phaseTwo"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>\"I am alive today not because of insurance com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>As a former social worker, I've seen first-han...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Today, Vietnam War Veterans Day, we pause to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>\"It's humiliating. Honestly, Bern, it's humili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Words fail.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33771</th>\n",
              "      <td>0.0</td>\n",
              "      <td>The Senate just voted to begin debate on the f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33772</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Reminder:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33773</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NEW AD: Washington is rigged for the well-conn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33774</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Happy Birthday,  45! We hope youre able to fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33775</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I work will work w you when you go back to th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33776 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       party                                               text\n",
              "0        1.0  \"I am alive today not because of insurance com...\n",
              "1        1.0  As a former social worker, I've seen first-han...\n",
              "2        1.0  Today, Vietnam War Veterans Day, we pause to h...\n",
              "3        1.0  \"It's humiliating. Honestly, Bern, it's humili...\n",
              "4        1.0                                        Words fail.\n",
              "...      ...                                                ...\n",
              "33771    0.0  The Senate just voted to begin debate on the f...\n",
              "33772    1.0                                         Reminder: \n",
              "33773    0.0  NEW AD: Washington is rigged for the well-conn...\n",
              "33774    0.0  Happy Birthday,  45! We hope youre able to fin...\n",
              "33775    0.0   I work will work w you when you go back to th...\n",
              "\n",
              "[33776 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X5iMdZsw7I7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "81db723f-e22e-4ce2-a1f9-1a8ed1b080c1"
      },
      "source": [
        "tweets = phaseTwo.text.values\n",
        "labels = phaseTwo.party.values\n",
        "\n",
        "input_ids = []\n",
        "\n",
        "for tweet in tweets:\n",
        "  encoded_tweet = tokenizer.encode(tweet,add_special_tokens=True)\n",
        "\n",
        "  input_ids.append(encoded_tweet)\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "input_ids = pad_sequences(input_ids,maxlen=MAX_LEN,dtype='long',truncating='post',padding='post')\n",
        "\n",
        "for tweet in input_ids:\n",
        "  tweet_mask = [float(i > 0) for i in tweet]\n",
        "  attention_masks.append(tweet_mask)\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs,prediction_masks,prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data,sampler=prediction_sampler,batch_size=batch_size)\n",
        "\n",
        "print('Number of test sentences: {:,}\\n'.format(phaseTwo.shape[0]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 33,776\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rVzOQpGzuns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98a70c42-584a-467c-dc34-6a54d7f35cc6"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions, true_labels = [],[]\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids,token_type_ids  = None,attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 33,776 test sentences...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohphXa451bEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57f30f22-92be-4e1c-cf95-80328f6acaed"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (phaseTwo.party.sum(), len(phaseTwo.party), (phaseTwo.party.sum() / len(phaseTwo.party) * 100.0)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 22416 of 33776 (66.37%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA89_lGe2e3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i],axis=1).flatten()\n",
        "\n",
        "  matthews = matthews_corrcoef(true_labels[i],pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkjeWCA43Fqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17080699-e65c-4d63-fd75-4ea4eeb7c8cd"
      },
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions,axis=1).flatten()\n",
        "\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "mcc = matthews_corrcoef(flat_true_labels,flat_predictions)\n",
        "\n",
        "print('MCC: %.5f'%mcc)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.66273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TvHseEO3wHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def analyze_slant(text):\n",
        "  encoded_tweet = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "  encoded_tweet = pad_sequences([encoded_tweet],maxlen=MAX_LEN,dtype='long',truncating='post',padding='post')\n",
        "\n",
        "  attention_mask = [[float(i > 0) for i in encoded_tweet[0]]]\n",
        "\n",
        "  encoded_tweet = torch.tensor(encoded_tweet).to(device)\n",
        "  attention_mask = torch.tensor(attention_mask).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(encoded_tweet,token_type_ids=None,attention_mask=attention_mask)\n",
        "\n",
        "  logits = outputs[0].detach().cpu().numpy()\n",
        "  return np.argmax(logits,axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YwGfJGc-Bus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def left_or_right(text):\n",
        "  return \"Left\" if analyze_slant(text)==1 else \"Right\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDa7O_ShAuCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9af896c-df70-4fb9-eb59-ed977fcfbe94"
      },
      "source": [
        "left_or_right(\"Legalize marijuana\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Left'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7wJWzy0Ax67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9267e19c-b0a3-48da-9332-8443fde6c625"
      },
      "source": [
        "left_or_right(\"MAGA\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Left'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMnEVEFEBE4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e62ac35-af94-447b-cd0f-b3d671410e9d"
      },
      "source": [
        "left_or_right(\"We need to build a wall\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Left'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HypwEUf8BUjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0809cf0f-bdad-4afe-dc88-7a0d604414a3"
      },
      "source": [
        "left_or_right(\"We need to build a wall.\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Left'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd5TJfTHCBjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "72d1c5c5-f4e7-430c-b1af-2d5bdf2f7844"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = './SlantClassification/model/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "print('Saving...')\n",
        "\n",
        "model_to_save = model.module if hasattr(model,'module') else model\n",
        "\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./SlantClassification/model/vocab.txt',\n",
              " './SlantClassification/model/special_tokens_map.json',\n",
              " './SlantClassification/model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7oHYvNpE0rg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dda0ef1-8f78-44dd-b3ac-3d9e5bc73311"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  SlantClassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLgZ6iE5E3N9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2b60882f-de01-42a8-b92e-b961db422e28"
      },
      "source": [
        "!zip -r model ./model"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tzip warning: name not matched: ./model\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r model . -i ./model)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCLqcrvuE_iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}