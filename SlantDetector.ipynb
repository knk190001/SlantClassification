{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SlantDetector.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgQ4ANHpXQR8KcA1sz8Wu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63a7f48e912a49c0815ea93e8fcb40c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ff99a80420a4e89aec3cbc063eba852",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f52cee80bd144bbbca01ecb7bec6aa3",
              "IPY_MODEL_9bf388d7197c4ff59f23ffbc09a51f1c"
            ]
          }
        },
        "1ff99a80420a4e89aec3cbc063eba852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f52cee80bd144bbbca01ecb7bec6aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f6db81d1fa6742dfafc45beacec1a543",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a949a02ae93471fa4a21a892c1580e0"
          }
        },
        "9bf388d7197c4ff59f23ffbc09a51f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b00014791a9d417cbfb3a99b9c0b79e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 2.65MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13c08e118032492b9bd21d3f9f6ea8d6"
          }
        },
        "f6db81d1fa6742dfafc45beacec1a543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a949a02ae93471fa4a21a892c1580e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b00014791a9d417cbfb3a99b9c0b79e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13c08e118032492b9bd21d3f9f6ea8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bf032a73d524f00964696a33ab00a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0cdefa4dd194f799e71d494cc3a3430",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f84a4b8649344298aa59b7d98c147a7",
              "IPY_MODEL_1206942fe15941b6b9ee78f9c7b6b15d"
            ]
          }
        },
        "e0cdefa4dd194f799e71d494cc3a3430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f84a4b8649344298aa59b7d98c147a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7745f88788143158287749ace723cfc",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99763726489c478c95c0abe70c16b2ef"
          }
        },
        "1206942fe15941b6b9ee78f9c7b6b15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0eab028dd524f1d81931b171e5963a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 16.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fb16c9af2b945dd82bff256fd685472"
          }
        },
        "c7745f88788143158287749ace723cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99763726489c478c95c0abe70c16b2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0eab028dd524f1d81931b171e5963a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fb16c9af2b945dd82bff256fd685472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2e7db0071774f2592bb8b41bcc3c647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_39e0f9dc7575425bb967d7f729b255dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fbdc02a8ffd34ba59b4b9801841c2228",
              "IPY_MODEL_1d15af2b8bbf44eeaf6f7c63113f07cb"
            ]
          }
        },
        "39e0f9dc7575425bb967d7f729b255dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbdc02a8ffd34ba59b4b9801841c2228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3867c93d2e904286b7f2e60ddfaed8f5",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fc09d76db3c46cda835552a28fd46ee"
          }
        },
        "1d15af2b8bbf44eeaf6f7c63113f07cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a0ec0e2167044a1a9d14d5eb6ccaf41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:06&lt;00:00, 71.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_201c4431e53c43568c8e6d0e6a943401"
          }
        },
        "3867c93d2e904286b7f2e60ddfaed8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fc09d76db3c46cda835552a28fd46ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a0ec0e2167044a1a9d14d5eb6ccaf41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "201c4431e53c43568c8e6d0e6a943401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knk190001/SlantClassification/blob/master/SlantDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4s_T-tJIZyW",
        "colab_type": "code",
        "outputId": "3dbe4b31-d582-4ad4-e020-6229d11ab8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/knk190001/SlantClassification.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SlantClassification'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 22 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtFwHuT91ZEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txLKd6x711r9",
        "colab_type": "code",
        "outputId": "f393ed41-5389-4ef0-9b46-aa3bbb133816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data = pd.read_csv('./SlantClassification/tweets.csv')\n",
        "reps = pd.read_json('./SlantClassification/representatives.json')\n",
        "sens = pd.read_json('./SlantClassification/senators.json')\n",
        "\n",
        "def findParty(user):\n",
        "  temp = reps[reps['Twitter_username']==user]\n",
        "  if temp.empty :\n",
        "    temp = sens[sens['Twitter_username']==user]\n",
        "  \n",
        "  if temp.empty:\n",
        "    return\n",
        "  if temp.iloc[0,2] == 'Democratic Party' :\n",
        "    return int(1)\n",
        "  elif temp.iloc[0,2] == 'Republican Party' :\n",
        "    return int(0)\n",
        "\n",
        "data['user'] = data['user'].apply(findParty)\n",
        "\n",
        "data.sample(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>83821</th>\n",
              "      <td>0.0</td>\n",
              "      <td>While I support the bipartisan, good-faith eff...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68828</th>\n",
              "      <td>1.0</td>\n",
              "      <td>President Trump's budget proposal lacks invest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93587</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Washington Lobbying Firm Pays Evan Bayh $2 Mil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130798</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Trumps thirst for self-enrichment knows no bou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>1.0</td>\n",
              "      <td>What Evelyn Yang is doing is incredibly brave....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        user                                               text\n",
              "83821    0.0  While I support the bipartisan, good-faith eff...\n",
              "68828    1.0  President Trump's budget proposal lacks invest...\n",
              "93587    0.0  Washington Lobbying Firm Pays Evan Bayh $2 Mil...\n",
              "130798   1.0  Trumps thirst for self-enrichment knows no bou...\n",
              "523      1.0  What Evelyn Yang is doing is incredibly brave...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvBtKeLGjrcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def remove(pattern,text):\n",
        "  if isinstance(text,str):\n",
        "    return re.sub(pattern,'',text)\n",
        "  return float('nan')\n",
        "\n",
        "def removeLinks(text):\n",
        "  return remove(r'https?:\\/\\/.*[\\r\\n]*',text)\n",
        "def removeHandles(text):\n",
        "  return remove(r'@\\w{1,15}',text)\n",
        "def removeHashtags(text):\n",
        "  return remove(r'#\\w*[A-Za-z_]+\\w*',text)\n",
        "\n",
        "data['text'] = data['text'].apply(removeLinks).apply(removeHandles).apply(removeHashtags).dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUPqVo5QYs0q",
        "colab_type": "code",
        "outputId": "1b0be5a3-fa37-402b-d9be-5bea1161c66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "data.columns = ['party','text']\n",
        "data = data.dropna()\n",
        "data.head(20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Nancy Pelosi and Adam Schiffs impeachment was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>One of the reasons for the Democrats' impeachm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>It was great to see so many friends tonight at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>READ MY FULL STATEMENT HERE:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. is a foot soldier for Chuck Schumer and the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. is deeply complicit in this grave wrong. In ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>They fear our strong President  who is boldly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>House Democrats have committed a very grave wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>As I have stated from the beginning on multipl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>The Democrats partisan impeachment charade has...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I commend President  for his strong and commit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>RT : EXCLUSIVE  : Doug Jones Has Revealed Hims...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. is a foot soldier for  and the radical left,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. announced this morning that he plans to vote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>So happy for my good friend Rush Limbaugh  Rus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Amen. Thank you, President Trump, for protecti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>The left has swung and missed on impeachment. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Truly an incredible State of the Union address...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I'll be on Fox News tonight with  to preview P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>No one has done more to advance the cause of f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    party                                               text\n",
              "1     0.0  Nancy Pelosi and Adam Schiffs impeachment was ...\n",
              "2     0.0  One of the reasons for the Democrats' impeachm...\n",
              "3     0.0  It was great to see so many friends tonight at...\n",
              "4     0.0                      READ MY FULL STATEMENT HERE: \n",
              "5     0.0  . is a foot soldier for Chuck Schumer and the ...\n",
              "6     0.0  . is deeply complicit in this grave wrong. In ...\n",
              "7     0.0  They fear our strong President  who is boldly ...\n",
              "8     0.0  House Democrats have committed a very grave wr...\n",
              "9     0.0  As I have stated from the beginning on multipl...\n",
              "10    0.0  The Democrats partisan impeachment charade has...\n",
              "11    0.0  I commend President  for his strong and commit...\n",
              "12    0.0  RT : EXCLUSIVE  : Doug Jones Has Revealed Hims...\n",
              "13    0.0  . is a foot soldier for  and the radical left,...\n",
              "14    0.0  . announced this morning that he plans to vote...\n",
              "15    0.0  So happy for my good friend Rush Limbaugh  Rus...\n",
              "16    0.0  Amen. Thank you, President Trump, for protecti...\n",
              "17    0.0  The left has swung and missed on impeachment. ...\n",
              "18    0.0  Truly an incredible State of the Union address...\n",
              "19    0.0  I'll be on Fox News tonight with  to preview P...\n",
              "20    0.0  No one has done more to advance the cause of f..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hkK3qMtMcVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "7b7b435c-f1e1-4180-8e41-d815da765754"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 3.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 41.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=616e9feb27eacdbf353a25d498579ecca41ea9748a8c215dc78027bd928e2b02\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNe_O6CTMhyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERE0QpoQ2c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True).dropna()\n",
        "phaseOne = data.head(int(len(data.index) * .75)).reset_index(drop=True)\n",
        "phaseTwo = data.tail(int(len(data.index)*.25)).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDXZw0glTrn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "99ee3886-8ae5-4190-dbf4-90237ee2fc5d"
      },
      "source": [
        "phaseOne"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>We are not only going to legalize marijuana; w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>. : \"John McCain fights cancer and finds ... j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Judge Gorsuch has ruled against disabled stude...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Yesterday Verne and I celebrated 32 years of m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Unbelievably moving to join  family for long o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101324</th>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101325</th>\n",
              "      <td>0.0</td>\n",
              "      <td>RT this if you think kids and families deserve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101326</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Today at 10amET, I'll join  on  in-studio from...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101327</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Congratulations to  &amp;amp; Melanie!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101328</th>\n",
              "      <td>0.0</td>\n",
              "      <td>This week during , let's take a moment to reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101329 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        party                                               text\n",
              "0         1.0  We are not only going to legalize marijuana; w...\n",
              "1         0.0  . : \"John McCain fights cancer and finds ... j...\n",
              "2         1.0  Judge Gorsuch has ruled against disabled stude...\n",
              "3         0.0  Yesterday Verne and I celebrated 32 years of m...\n",
              "4         1.0  Unbelievably moving to join  family for long o...\n",
              "...       ...                                                ...\n",
              "101324    1.0                                                   \n",
              "101325    0.0  RT this if you think kids and families deserve...\n",
              "101326    0.0  Today at 10amET, I'll join  on  in-studio from...\n",
              "101327    1.0               Congratulations to  &amp; Melanie!  \n",
              "101328    0.0  This week during , let's take a moment to reco...\n",
              "\n",
              "[101329 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flUKhSifXn5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1edd21c4-63f7-4eba-e312-54d2680ed0bb"
      },
      "source": [
        "phaseTwo"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Joe met with members of  and  to discuss the i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>If youre new to health care coverage or lookin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Alabamas extreme and unconstitutional ban on a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Today's 30th anniversary of the Tiananmen Squa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Great work  K-9 Sig &amp;amp; Officer Hensel and  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33771</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Untruthful testimony, under oath and on the re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33772</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HAPPENING NOW: Judge Kavanaugh must honestly a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33773</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Happy Birthday CT! On the 232nd anniversary of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33774</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I partnered w/  to reintroduce the Reach Act t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33775</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Senator Collins just cast her 4,900th consecut...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33776 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       party                                               text\n",
              "0        1.0  Joe met with members of  and  to discuss the i...\n",
              "1        1.0  If youre new to health care coverage or lookin...\n",
              "2        1.0  Alabamas extreme and unconstitutional ban on a...\n",
              "3        0.0  Today's 30th anniversary of the Tiananmen Squa...\n",
              "4        0.0  Great work  K-9 Sig &amp; Officer Hensel and  ...\n",
              "...      ...                                                ...\n",
              "33771    1.0  Untruthful testimony, under oath and on the re...\n",
              "33772    1.0  HAPPENING NOW: Judge Kavanaugh must honestly a...\n",
              "33773    1.0  Happy Birthday CT! On the 232nd anniversary of...\n",
              "33774    0.0  I partnered w/  to reintroduce the Reach Act t...\n",
              "33775    0.0  Senator Collins just cast her 4,900th consecut...\n",
              "\n",
              "[33776 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpObFuC9Z7qN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fbcb966-03b1-46bf-c269-478cfc4aaf2c"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"cuda\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print('cpu')\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoUR3aS5am3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = phaseOne.text.values\n",
        "labels = phaseOne.party.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk2JXBeQivdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112,
          "referenced_widgets": [
            "63a7f48e912a49c0815ea93e8fcb40c7",
            "1ff99a80420a4e89aec3cbc063eba852",
            "9f52cee80bd144bbbca01ecb7bec6aa3",
            "9bf388d7197c4ff59f23ffbc09a51f1c",
            "f6db81d1fa6742dfafc45beacec1a543",
            "4a949a02ae93471fa4a21a892c1580e0",
            "b00014791a9d417cbfb3a99b9c0b79e0",
            "13c08e118032492b9bd21d3f9f6ea8d6"
          ]
        },
        "outputId": "b768b4c4-0c75-46c3-b140-c23186c9109a"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a7f48e912a49c0815ea93e8fcb40c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HGTznPtjAqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "917d34a5-94f2-4c23-9e6e-a18694fe129c"
      },
      "source": [
        "print('Original: ',tweets[0])\n",
        "print('Tokenized: ',tokenizer.tokenize(tweets[0]))\n",
        "print('Token IDs: ',tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  We are not only going to legalize marijuana; we are going to expunge past convictions for marijuana possession. Tha \n",
            "Tokenized:  ['we', 'are', 'not', 'only', 'going', 'to', 'legal', '##ize', 'marijuana', ';', 'we', 'are', 'going', 'to', 'ex', '##pu', '##nge', 'past', 'convictions', 'for', 'marijuana', 'possession', '.', 'tha']\n",
            "Token IDs:  [2057, 2024, 2025, 2069, 2183, 2000, 3423, 4697, 16204, 1025, 2057, 2024, 2183, 2000, 4654, 14289, 15465, 2627, 20488, 2005, 16204, 6664, 1012, 22794]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1SX682ujNIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "911476ff-5095-4178-94d4-062e6ed0884b"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for tweet in tweets:\n",
        "  encoded_tweet = tokenizer.encode(tweet,add_special_tokens=True)\n",
        "  input_ids.append(encoded_tweet)\n",
        "\n",
        "print('Max length: ', max([len(tweet) for tweet in input_ids]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHmWD0_bn4wQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "input_ids = pad_sequences(input_ids,maxlen=MAX_LEN,dtype='long',value=0, truncating='post',padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_fXmPbXodXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_mask = []\n",
        "\n",
        "for tweet in input_ids:\n",
        "  att_mask = [int(token_id>0) for token_id in tweet]\n",
        "  attention_mask.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oXqYGfcpIm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.model_selection import train_test_split\n",
        "\n",
        " train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,labels,random_state=2018,test_size=0.1)\n",
        "\n",
        " train_masks, validation_masks, _, _, = train_test_split(attention_mask,labels,random_state=2018,test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmVcP5ZwqOVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2KlsJPMrnIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs,train_masks,train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs,validation_masks,validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkrxCnlbsoFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7bf032a73d524f00964696a33ab00a3a",
            "e0cdefa4dd194f799e71d494cc3a3430",
            "4f84a4b8649344298aa59b7d98c147a7",
            "1206942fe15941b6b9ee78f9c7b6b15d",
            "c7745f88788143158287749ace723cfc",
            "99763726489c478c95c0abe70c16b2ef",
            "f0eab028dd524f1d81931b171e5963a5",
            "7fb16c9af2b945dd82bff256fd685472",
            "a2e7db0071774f2592bb8b41bcc3c647",
            "39e0f9dc7575425bb967d7f729b255dd",
            "fbdc02a8ffd34ba59b4b9801841c2228",
            "1d15af2b8bbf44eeaf6f7c63113f07cb",
            "3867c93d2e904286b7f2e60ddfaed8f5",
            "8fc09d76db3c46cda835552a28fd46ee",
            "5a0ec0e2167044a1a9d14d5eb6ccaf41",
            "201c4431e53c43568c8e6d0e6a943401"
          ]
        },
        "outputId": "3fc3ceae-1f18-4b8c-b9ec-6fee8c89a753"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bf032a73d524f00964696a33ab00a3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2e7db0071774f2592bb8b41bcc3c647",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12pfRJ1rtE8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsx0GkPtdK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader)*epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBl5Mj-FtxZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds,labels):\n",
        "  pred_flat = np.argmax(preds,axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat==labels_flat)/len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynsd4V12uI3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE6jIktBuduM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc1e944a-8e8b-4652-a55b-f357fbf705f0"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0,epochs):\n",
        "  print('')\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  print('Training...')\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].long().to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids,token_type_ids = None, attention_mask = b_input_mask,labels=b_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "  avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  loss_values.append(avg_train_loss)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  eval_loss,eval_accuracy=0,0\n",
        "  nb_eval_steps,nb_eval_examples = 0,0\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(b_input_ids,token_type_ids = None,attention_mask = b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits,label_ids)\n",
        "\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_steps += 1\n",
        "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  2,850.    Elapsed: 0:00:15.\n",
            "  Batch    80  of  2,850.    Elapsed: 0:00:30.\n",
            "  Batch   120  of  2,850.    Elapsed: 0:00:46.\n",
            "  Batch   160  of  2,850.    Elapsed: 0:01:02.\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:18.\n",
            "  Batch   240  of  2,850.    Elapsed: 0:01:34.\n",
            "  Batch   280  of  2,850.    Elapsed: 0:01:51.\n",
            "  Batch   320  of  2,850.    Elapsed: 0:02:08.\n",
            "  Batch   360  of  2,850.    Elapsed: 0:02:24.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:40.\n",
            "  Batch   440  of  2,850.    Elapsed: 0:02:57.\n",
            "  Batch   480  of  2,850.    Elapsed: 0:03:13.\n",
            "  Batch   520  of  2,850.    Elapsed: 0:03:30.\n",
            "  Batch   560  of  2,850.    Elapsed: 0:03:46.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:04:03.\n",
            "  Batch   640  of  2,850.    Elapsed: 0:04:19.\n",
            "  Batch   680  of  2,850.    Elapsed: 0:04:35.\n",
            "  Batch   720  of  2,850.    Elapsed: 0:04:52.\n",
            "  Batch   760  of  2,850.    Elapsed: 0:05:08.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:25.\n",
            "  Batch   840  of  2,850.    Elapsed: 0:05:41.\n",
            "  Batch   880  of  2,850.    Elapsed: 0:05:58.\n",
            "  Batch   920  of  2,850.    Elapsed: 0:06:14.\n",
            "  Batch   960  of  2,850.    Elapsed: 0:06:30.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:47.\n",
            "  Batch 1,040  of  2,850.    Elapsed: 0:07:03.\n",
            "  Batch 1,080  of  2,850.    Elapsed: 0:07:20.\n",
            "  Batch 1,120  of  2,850.    Elapsed: 0:07:36.\n",
            "  Batch 1,160  of  2,850.    Elapsed: 0:07:53.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:09.\n",
            "  Batch 1,240  of  2,850.    Elapsed: 0:08:25.\n",
            "  Batch 1,280  of  2,850.    Elapsed: 0:08:42.\n",
            "  Batch 1,320  of  2,850.    Elapsed: 0:08:58.\n",
            "  Batch 1,360  of  2,850.    Elapsed: 0:09:15.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:31.\n",
            "  Batch 1,440  of  2,850.    Elapsed: 0:09:48.\n",
            "  Batch 1,480  of  2,850.    Elapsed: 0:10:04.\n",
            "  Batch 1,520  of  2,850.    Elapsed: 0:10:21.\n",
            "  Batch 1,560  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:53.\n",
            "  Batch 1,640  of  2,850.    Elapsed: 0:11:10.\n",
            "  Batch 1,680  of  2,850.    Elapsed: 0:11:26.\n",
            "  Batch 1,720  of  2,850.    Elapsed: 0:11:43.\n",
            "  Batch 1,760  of  2,850.    Elapsed: 0:11:59.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:12:15.\n",
            "  Batch 1,840  of  2,850.    Elapsed: 0:12:32.\n",
            "  Batch 1,880  of  2,850.    Elapsed: 0:12:48.\n",
            "  Batch 1,920  of  2,850.    Elapsed: 0:13:05.\n",
            "  Batch 1,960  of  2,850.    Elapsed: 0:13:21.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:38.\n",
            "  Batch 2,040  of  2,850.    Elapsed: 0:13:54.\n",
            "  Batch 2,080  of  2,850.    Elapsed: 0:14:10.\n",
            "  Batch 2,120  of  2,850.    Elapsed: 0:14:27.\n",
            "  Batch 2,160  of  2,850.    Elapsed: 0:14:43.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:15:00.\n",
            "  Batch 2,240  of  2,850.    Elapsed: 0:15:16.\n",
            "  Batch 2,280  of  2,850.    Elapsed: 0:15:33.\n",
            "  Batch 2,320  of  2,850.    Elapsed: 0:15:49.\n",
            "  Batch 2,360  of  2,850.    Elapsed: 0:16:05.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:22.\n",
            "  Batch 2,440  of  2,850.    Elapsed: 0:16:38.\n",
            "  Batch 2,480  of  2,850.    Elapsed: 0:16:55.\n",
            "  Batch 2,520  of  2,850.    Elapsed: 0:17:11.\n",
            "  Batch 2,560  of  2,850.    Elapsed: 0:17:28.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:44.\n",
            "  Batch 2,640  of  2,850.    Elapsed: 0:18:01.\n",
            "  Batch 2,680  of  2,850.    Elapsed: 0:18:17.\n",
            "  Batch 2,720  of  2,850.    Elapsed: 0:18:33.\n",
            "  Batch 2,760  of  2,850.    Elapsed: 0:18:50.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:06.\n",
            "  Batch 2,840  of  2,850.    Elapsed: 0:19:23.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:19:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  2,850.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  2,850.    Elapsed: 0:00:33.\n",
            "  Batch   120  of  2,850.    Elapsed: 0:00:49.\n",
            "  Batch   160  of  2,850.    Elapsed: 0:01:06.\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:22.\n",
            "  Batch   240  of  2,850.    Elapsed: 0:01:39.\n",
            "  Batch   280  of  2,850.    Elapsed: 0:01:55.\n",
            "  Batch   320  of  2,850.    Elapsed: 0:02:11.\n",
            "  Batch   360  of  2,850.    Elapsed: 0:02:28.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:44.\n",
            "  Batch   440  of  2,850.    Elapsed: 0:03:01.\n",
            "  Batch   480  of  2,850.    Elapsed: 0:03:17.\n",
            "  Batch   520  of  2,850.    Elapsed: 0:03:33.\n",
            "  Batch   560  of  2,850.    Elapsed: 0:03:50.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:04:06.\n",
            "  Batch   640  of  2,850.    Elapsed: 0:04:23.\n",
            "  Batch   680  of  2,850.    Elapsed: 0:04:39.\n",
            "  Batch   720  of  2,850.    Elapsed: 0:04:55.\n",
            "  Batch   760  of  2,850.    Elapsed: 0:05:12.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:28.\n",
            "  Batch   840  of  2,850.    Elapsed: 0:05:45.\n",
            "  Batch   880  of  2,850.    Elapsed: 0:06:01.\n",
            "  Batch   920  of  2,850.    Elapsed: 0:06:17.\n",
            "  Batch   960  of  2,850.    Elapsed: 0:06:34.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:50.\n",
            "  Batch 1,040  of  2,850.    Elapsed: 0:07:07.\n",
            "  Batch 1,080  of  2,850.    Elapsed: 0:07:23.\n",
            "  Batch 1,120  of  2,850.    Elapsed: 0:07:40.\n",
            "  Batch 1,160  of  2,850.    Elapsed: 0:07:56.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:13.\n",
            "  Batch 1,240  of  2,850.    Elapsed: 0:08:29.\n",
            "  Batch 1,280  of  2,850.    Elapsed: 0:08:45.\n",
            "  Batch 1,320  of  2,850.    Elapsed: 0:09:02.\n",
            "  Batch 1,360  of  2,850.    Elapsed: 0:09:18.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:35.\n",
            "  Batch 1,440  of  2,850.    Elapsed: 0:09:51.\n",
            "  Batch 1,480  of  2,850.    Elapsed: 0:10:08.\n",
            "  Batch 1,520  of  2,850.    Elapsed: 0:10:24.\n",
            "  Batch 1,560  of  2,850.    Elapsed: 0:10:40.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:57.\n",
            "  Batch 1,640  of  2,850.    Elapsed: 0:11:13.\n",
            "  Batch 1,680  of  2,850.    Elapsed: 0:11:30.\n",
            "  Batch 1,720  of  2,850.    Elapsed: 0:11:46.\n",
            "  Batch 1,760  of  2,850.    Elapsed: 0:12:02.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:12:19.\n",
            "  Batch 1,840  of  2,850.    Elapsed: 0:12:35.\n",
            "  Batch 1,880  of  2,850.    Elapsed: 0:12:52.\n",
            "  Batch 1,920  of  2,850.    Elapsed: 0:13:08.\n",
            "  Batch 1,960  of  2,850.    Elapsed: 0:13:25.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:41.\n",
            "  Batch 2,040  of  2,850.    Elapsed: 0:13:57.\n",
            "  Batch 2,080  of  2,850.    Elapsed: 0:14:14.\n",
            "  Batch 2,120  of  2,850.    Elapsed: 0:14:30.\n",
            "  Batch 2,160  of  2,850.    Elapsed: 0:14:47.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:15:03.\n",
            "  Batch 2,240  of  2,850.    Elapsed: 0:15:19.\n",
            "  Batch 2,280  of  2,850.    Elapsed: 0:15:36.\n",
            "  Batch 2,320  of  2,850.    Elapsed: 0:15:52.\n",
            "  Batch 2,360  of  2,850.    Elapsed: 0:16:09.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:25.\n",
            "  Batch 2,440  of  2,850.    Elapsed: 0:16:41.\n",
            "  Batch 2,480  of  2,850.    Elapsed: 0:16:58.\n",
            "  Batch 2,520  of  2,850.    Elapsed: 0:17:14.\n",
            "  Batch 2,560  of  2,850.    Elapsed: 0:17:31.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:47.\n",
            "  Batch 2,640  of  2,850.    Elapsed: 0:18:04.\n",
            "  Batch 2,680  of  2,850.    Elapsed: 0:18:20.\n",
            "  Batch 2,720  of  2,850.    Elapsed: 0:18:36.\n",
            "  Batch 2,760  of  2,850.    Elapsed: 0:18:53.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:09.\n",
            "  Batch 2,840  of  2,850.    Elapsed: 0:19:25.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:19:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  2,850.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  2,850.    Elapsed: 0:00:33.\n",
            "  Batch   120  of  2,850.    Elapsed: 0:00:49.\n",
            "  Batch   160  of  2,850.    Elapsed: 0:01:06.\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:22.\n",
            "  Batch   240  of  2,850.    Elapsed: 0:01:39.\n",
            "  Batch   280  of  2,850.    Elapsed: 0:01:55.\n",
            "  Batch   320  of  2,850.    Elapsed: 0:02:11.\n",
            "  Batch   360  of  2,850.    Elapsed: 0:02:28.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:44.\n",
            "  Batch   440  of  2,850.    Elapsed: 0:03:01.\n",
            "  Batch   480  of  2,850.    Elapsed: 0:03:17.\n",
            "  Batch   520  of  2,850.    Elapsed: 0:03:33.\n",
            "  Batch   560  of  2,850.    Elapsed: 0:03:50.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:04:06.\n",
            "  Batch   640  of  2,850.    Elapsed: 0:04:23.\n",
            "  Batch   680  of  2,850.    Elapsed: 0:04:39.\n",
            "  Batch   720  of  2,850.    Elapsed: 0:04:56.\n",
            "  Batch   760  of  2,850.    Elapsed: 0:05:12.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:28.\n",
            "  Batch   840  of  2,850.    Elapsed: 0:05:45.\n",
            "  Batch   880  of  2,850.    Elapsed: 0:06:01.\n",
            "  Batch   920  of  2,850.    Elapsed: 0:06:18.\n",
            "  Batch   960  of  2,850.    Elapsed: 0:06:34.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:51.\n",
            "  Batch 1,040  of  2,850.    Elapsed: 0:07:07.\n",
            "  Batch 1,080  of  2,850.    Elapsed: 0:07:23.\n",
            "  Batch 1,120  of  2,850.    Elapsed: 0:07:40.\n",
            "  Batch 1,160  of  2,850.    Elapsed: 0:07:56.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:13.\n",
            "  Batch 1,240  of  2,850.    Elapsed: 0:08:29.\n",
            "  Batch 1,280  of  2,850.    Elapsed: 0:08:46.\n",
            "  Batch 1,320  of  2,850.    Elapsed: 0:09:02.\n",
            "  Batch 1,360  of  2,850.    Elapsed: 0:09:19.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:35.\n",
            "  Batch 1,440  of  2,850.    Elapsed: 0:09:51.\n",
            "  Batch 1,480  of  2,850.    Elapsed: 0:10:08.\n",
            "  Batch 1,520  of  2,850.    Elapsed: 0:10:24.\n",
            "  Batch 1,560  of  2,850.    Elapsed: 0:10:41.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:57.\n",
            "  Batch 1,640  of  2,850.    Elapsed: 0:11:13.\n",
            "  Batch 1,680  of  2,850.    Elapsed: 0:11:30.\n",
            "  Batch 1,720  of  2,850.    Elapsed: 0:11:46.\n",
            "  Batch 1,760  of  2,850.    Elapsed: 0:12:03.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:12:19.\n",
            "  Batch 1,840  of  2,850.    Elapsed: 0:12:35.\n",
            "  Batch 1,880  of  2,850.    Elapsed: 0:12:52.\n",
            "  Batch 1,920  of  2,850.    Elapsed: 0:13:08.\n",
            "  Batch 1,960  of  2,850.    Elapsed: 0:13:25.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:41.\n",
            "  Batch 2,040  of  2,850.    Elapsed: 0:13:58.\n",
            "  Batch 2,080  of  2,850.    Elapsed: 0:14:14.\n",
            "  Batch 2,120  of  2,850.    Elapsed: 0:14:31.\n",
            "  Batch 2,160  of  2,850.    Elapsed: 0:14:47.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:15:03.\n",
            "  Batch 2,240  of  2,850.    Elapsed: 0:15:20.\n",
            "  Batch 2,280  of  2,850.    Elapsed: 0:15:36.\n",
            "  Batch 2,320  of  2,850.    Elapsed: 0:15:53.\n",
            "  Batch 2,360  of  2,850.    Elapsed: 0:16:09.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:25.\n",
            "  Batch 2,440  of  2,850.    Elapsed: 0:16:42.\n",
            "  Batch 2,480  of  2,850.    Elapsed: 0:16:58.\n",
            "  Batch 2,520  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,560  of  2,850.    Elapsed: 0:17:31.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:48.\n",
            "  Batch 2,640  of  2,850.    Elapsed: 0:18:04.\n",
            "  Batch 2,680  of  2,850.    Elapsed: 0:18:20.\n",
            "  Batch 2,720  of  2,850.    Elapsed: 0:18:37.\n",
            "  Batch 2,760  of  2,850.    Elapsed: 0:18:53.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:10.\n",
            "  Batch 2,840  of  2,850.    Elapsed: 0:19:26.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:19:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  2,850.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  2,850.    Elapsed: 0:00:33.\n",
            "  Batch   120  of  2,850.    Elapsed: 0:00:49.\n",
            "  Batch   160  of  2,850.    Elapsed: 0:01:06.\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:22.\n",
            "  Batch   240  of  2,850.    Elapsed: 0:01:39.\n",
            "  Batch   280  of  2,850.    Elapsed: 0:01:55.\n",
            "  Batch   320  of  2,850.    Elapsed: 0:02:11.\n",
            "  Batch   360  of  2,850.    Elapsed: 0:02:28.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:44.\n",
            "  Batch   440  of  2,850.    Elapsed: 0:03:01.\n",
            "  Batch   480  of  2,850.    Elapsed: 0:03:17.\n",
            "  Batch   520  of  2,850.    Elapsed: 0:03:34.\n",
            "  Batch   560  of  2,850.    Elapsed: 0:03:50.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:04:06.\n",
            "  Batch   640  of  2,850.    Elapsed: 0:04:23.\n",
            "  Batch   680  of  2,850.    Elapsed: 0:04:39.\n",
            "  Batch   720  of  2,850.    Elapsed: 0:04:56.\n",
            "  Batch   760  of  2,850.    Elapsed: 0:05:12.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:29.\n",
            "  Batch   840  of  2,850.    Elapsed: 0:05:45.\n",
            "  Batch   880  of  2,850.    Elapsed: 0:06:01.\n",
            "  Batch   920  of  2,850.    Elapsed: 0:06:18.\n",
            "  Batch   960  of  2,850.    Elapsed: 0:06:34.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:51.\n",
            "  Batch 1,040  of  2,850.    Elapsed: 0:07:07.\n",
            "  Batch 1,080  of  2,850.    Elapsed: 0:07:23.\n",
            "  Batch 1,120  of  2,850.    Elapsed: 0:07:40.\n",
            "  Batch 1,160  of  2,850.    Elapsed: 0:07:56.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:08:13.\n",
            "  Batch 1,240  of  2,850.    Elapsed: 0:08:29.\n",
            "  Batch 1,280  of  2,850.    Elapsed: 0:08:46.\n",
            "  Batch 1,320  of  2,850.    Elapsed: 0:09:02.\n",
            "  Batch 1,360  of  2,850.    Elapsed: 0:09:19.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:35.\n",
            "  Batch 1,440  of  2,850.    Elapsed: 0:09:51.\n",
            "  Batch 1,480  of  2,850.    Elapsed: 0:10:08.\n",
            "  Batch 1,520  of  2,850.    Elapsed: 0:10:24.\n",
            "  Batch 1,560  of  2,850.    Elapsed: 0:10:41.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:57.\n",
            "  Batch 1,640  of  2,850.    Elapsed: 0:11:13.\n",
            "  Batch 1,680  of  2,850.    Elapsed: 0:11:30.\n",
            "  Batch 1,720  of  2,850.    Elapsed: 0:11:46.\n",
            "  Batch 1,760  of  2,850.    Elapsed: 0:12:03.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:12:19.\n",
            "  Batch 1,840  of  2,850.    Elapsed: 0:12:35.\n",
            "  Batch 1,880  of  2,850.    Elapsed: 0:12:52.\n",
            "  Batch 1,920  of  2,850.    Elapsed: 0:13:08.\n",
            "  Batch 1,960  of  2,850.    Elapsed: 0:13:25.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:41.\n",
            "  Batch 2,040  of  2,850.    Elapsed: 0:13:58.\n",
            "  Batch 2,080  of  2,850.    Elapsed: 0:14:14.\n",
            "  Batch 2,120  of  2,850.    Elapsed: 0:14:30.\n",
            "  Batch 2,160  of  2,850.    Elapsed: 0:14:47.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:15:03.\n",
            "  Batch 2,240  of  2,850.    Elapsed: 0:15:20.\n",
            "  Batch 2,280  of  2,850.    Elapsed: 0:15:36.\n",
            "  Batch 2,320  of  2,850.    Elapsed: 0:15:53.\n",
            "  Batch 2,360  of  2,850.    Elapsed: 0:16:09.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:16:25.\n",
            "  Batch 2,440  of  2,850.    Elapsed: 0:16:42.\n",
            "  Batch 2,480  of  2,850.    Elapsed: 0:16:58.\n",
            "  Batch 2,520  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,560  of  2,850.    Elapsed: 0:17:31.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:47.\n",
            "  Batch 2,640  of  2,850.    Elapsed: 0:18:04.\n",
            "  Batch 2,680  of  2,850.    Elapsed: 0:18:20.\n",
            "  Batch 2,720  of  2,850.    Elapsed: 0:18:37.\n",
            "  Batch 2,760  of  2,850.    Elapsed: 0:18:53.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:19:09.\n",
            "  Batch 2,840  of  2,850.    Elapsed: 0:19:26.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:19:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:43\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE1CEng0zIWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "233b4996-d7e7-4d05-ec84-684901e4d29f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams['figure.figsize'] = (12,6)\n",
        "\n",
        "plt.plot(loss_values,'b-o')\n",
        "\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpEIE5F0s6es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "07d792de-289c-4830-9335-2ef1e6f5c997"
      },
      "source": [
        "phaseTwo"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>party</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Joe met with members of  and  to discuss the i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>If youre new to health care coverage or lookin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Alabamas extreme and unconstitutional ban on a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Today's 30th anniversary of the Tiananmen Squa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Great work  K-9 Sig &amp;amp; Officer Hensel and  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33771</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Untruthful testimony, under oath and on the re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33772</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HAPPENING NOW: Judge Kavanaugh must honestly a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33773</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Happy Birthday CT! On the 232nd anniversary of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33774</th>\n",
              "      <td>0.0</td>\n",
              "      <td>I partnered w/  to reintroduce the Reach Act t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33775</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Senator Collins just cast her 4,900th consecut...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33776 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       party                                               text\n",
              "0        1.0  Joe met with members of  and  to discuss the i...\n",
              "1        1.0  If youre new to health care coverage or lookin...\n",
              "2        1.0  Alabamas extreme and unconstitutional ban on a...\n",
              "3        0.0  Today's 30th anniversary of the Tiananmen Squa...\n",
              "4        0.0  Great work  K-9 Sig &amp; Officer Hensel and  ...\n",
              "...      ...                                                ...\n",
              "33771    1.0  Untruthful testimony, under oath and on the re...\n",
              "33772    1.0  HAPPENING NOW: Judge Kavanaugh must honestly a...\n",
              "33773    1.0  Happy Birthday CT! On the 232nd anniversary of...\n",
              "33774    0.0  I partnered w/  to reintroduce the Reach Act t...\n",
              "33775    0.0  Senator Collins just cast her 4,900th consecut...\n",
              "\n",
              "[33776 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X5iMdZsw7I7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "418d3590-7f22-41a1-91b5-2df3950ab3ca"
      },
      "source": [
        "tweets = phaseTwo.text.values\n",
        "labels = phaseTwo.party.values\n",
        "\n",
        "input_ids = []\n",
        "\n",
        "for tweet in tweets:\n",
        "  encoded_tweet = tokenizer.encode(tweet,add_special_tokens=True)\n",
        "\n",
        "  input_ids.append(encoded_tweet)\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "input_ids = pad_sequences(input_ids,maxlen=MAX_LEN,dtype='long',truncating='post',padding='post')\n",
        "\n",
        "for tweet in input_ids:\n",
        "  tweet_mask = [float(i > 0) for i in tweet]\n",
        "  attention_masks.append(tweet_mask)\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs,prediction_masks,prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data,sampler=prediction_sampler,batch_size=batch_size)\n",
        "\n",
        "print('Number of test sentences: {:,}\\n'.format(phaseTwo.shape[0]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 33,776\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rVzOQpGzuns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "11a69347-1da8-4f9d-a4e4-34d61a430914"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predictions, true_labels = [],[]\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids,token_type_ids  = None,attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 33,776 test sentences...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohphXa451bEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd38add4-820d-4de1-9579-4ede5977a8cd"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (phaseTwo.party.sum(), len(phaseTwo.party), (phaseTwo.party.sum() / len(phaseTwo.party) * 100.0)))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 22320 of 33776 (66.08%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA89_lGe2e3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i],axis=1).flatten()\n",
        "\n",
        "  matthews = matthews_corrcoef(true_labels[i],pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkjeWCA43Fqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dfa0117-1b9a-41b6-9e6c-c4a1448c961d"
      },
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions,axis=1).flatten()\n",
        "\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "mcc = matthews_corrcoef(flat_true_labels,flat_predictions)\n",
        "\n",
        "print('MCC: %.5f'%mcc)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.66319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TvHseEO3wHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def analyze_slant(text):\n",
        "  encoded_tweet = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "  encoded_tweet = pad_sequences([encoded_tweet],maxlen=MAX_LEN,dtype='long',truncating='post',padding='post')\n",
        "\n",
        "  attention_mask = [[float(i > 0) for i in encoded_tweet[0]]]\n",
        "\n",
        "  encoded_tweet = torch.tensor(encoded_tweet).to(device)\n",
        "  attention_mask = torch.tensor(attention_mask).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(encoded_tweet,token_type_ids=None,attention_mask=attention_mask)\n",
        "\n",
        "  logits = outputs[0].detach().cpu().numpy()\n",
        "  return np.argmax(logits,axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YwGfJGc-Bus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def left_or_right(text):\n",
        "  return \"Left\" if analyze_slant(text)==1 else \"Right\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDa7O_ShAuCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c648798-75f2-40aa-c67f-a62b19f61ba8"
      },
      "source": [
        "left_or_right(\"Legalize marijuana\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Left'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7wJWzy0Ax67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba4a885e-3daa-4f74-b110-4431ef29e59a"
      },
      "source": [
        "left_or_right(\"MAGA\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Left'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMnEVEFEBE4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4ca62a0-d7ba-4798-ba13-d7341639f423"
      },
      "source": [
        "left_or_right(\"We need to build a wall\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Right'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HypwEUf8BUjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67f7edea-2610-46d5-d2d6-f241b90d4f94"
      },
      "source": [
        "left_or_right(\"We need to build a wall.\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Left'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd5TJfTHCBjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c124ef82-7df8-42a5-90ae-04f24620632a"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = './SlantClassification/model/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "print('Saving...')\n",
        "\n",
        "model_to_save = model.module if hasattr(model,'module') else model\n",
        "\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./SlantClassification/model/vocab.txt',\n",
              " './SlantClassification/model/special_tokens_map.json',\n",
              " './SlantClassification/model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7oHYvNpE0rg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c467ca3a-66df-4233-fc90-94c323f242cf"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LICENSE  representatives.json  SlantDetector.ipynb\n",
            "model\t senators.json\t       tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLgZ6iE5E3N9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1673643e-ea9d-4690-b66a-71cdbe6d6178"
      },
      "source": [
        "!zip -r model ./model"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/tokenizer_config.json (stored 0%)\n",
            "  adding: model/config.json (deflated 55%)\n",
            "  adding: model/pytorch_model.bin (deflated 7%)\n",
            "  adding: model/vocab.txt (deflated 53%)\n",
            "  adding: model/special_tokens_map.json (deflated 40%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCLqcrvuE_iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}